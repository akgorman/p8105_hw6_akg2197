---
title: "p8105_hw6_akg2197"
author: "Annie Gorman"
date: "2024-12-01"
output: github_document
---

## Loading packages 

```{r, message=FALSE, echo=FALSE}
library(p8105.datasets)
library(tidyverse)
library(ggridges)
library(patchwork)
library(modelr)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)
```

# Problem 1 

### Loading data 

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

### Producing estimates of quintiles 

```{r}
bootstrap_est <- 
  replicate(5000, {
    boot_sample <- weather_df |> sample_frac(replace = TRUE)
    model <- lm(tmax ~ tmin, data = boot_sample)
    coefs <- coef(model)
    beta0 <- coefs[1]
    beta1 <- coefs[2]
    r_squared <- summary(model)$r.squared
    log_beta_product <- log(beta0 * beta1)
    c(r_squared, log_beta_product)
  }, simplify = "matrix") |>
  t() |>
  as.data.frame()

colnames(bootstrap_est) <- c("r_squared", "log_beta_product")

bootstrap_all <- bootstrap_est |>
  summarise(
    mean_r_squared = mean(r_squared),
    sd_r_squared = sd(r_squared),
    mean_log_beta_product = mean(log_beta_product),
    sd_log_beta_product = sd(log_beta_product)
  )

bootstrap_all
```
### distribution of R² estimates
```{r}
ggplot(bootstrap_est, aes(x = r_squared)) + 
  geom_histogram(bins = 30, fill = "skyblue", color = "black", alpha = 0.7) + 
  labs(
    title = "Bootstrap Distribution of R²",
    x = "R²",
    y = "Frequency"
  ) + 
  theme_minimal()
```

### distribution of log(β₀ * β₁) estimates
```{r}
ggplot(bootstrap_est, aes(x = log_beta_product)) + 
  geom_histogram(bins = 30, fill = "lightgreen", color = "black", alpha = 0.7) + 
  labs(
    title = "Bootstrap Distribution of log(β0 * β1)",
    x = "log(β0 * β1)",
    y = "Frequency"
  ) + 
  theme_minimal()
```

Both of these distributions for R^2 and log(beta0*beta1) appear to be somewhat normally distributed. The distribution for R^2 seems to be slightly left-skewed. 

### Confidence interval

```{r}
conf_results <- bootstrap_est |>
  summarise(
    r_squared_lower = quantile(r_squared, 0.025),
    r_squared_upper = quantile(r_squared, 0.975),
    log_beta_product_lower = quantile(log_beta_product, 0.025),
    log_beta_product_upper = quantile(log_beta_product, 0.975)
  ) |>
  print()
```

# Problem 2

### Loading data

```{r}
homicide_df <- read_csv("homicide-data.csv") |>
  mutate(city_state = map2(city, state, ~ paste(.x, .y, sep = ","))) |>  
  filter(!(city_state %in% c("Dallas,TX", "Phoenix,AZ", "Kansas City,MO", "Tulsa,AL"))) |> 
  mutate(
    solved = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest" ~ 0, 
      disposition == "Closed by arrest" ~ 1,
      TRUE ~ NA_real_  
    )
  ) |> 
  filter(victim_race %in% c("White", "Black")) |>  
  mutate(
    victim_age = as.numeric(victim_age)  
  )
```

### Baltimore, MD glm function

Obtaining the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims, keeping all other variables fixed.

```{r}
baltimore_df <- homicide_df |>
  filter(city_state == "Baltimore,MD") 

baltimore_reg <- glm(
  solved ~ victim_age + victim_sex + victim_race, 
  data = baltimore_df, 
  family = binomial()
)

baltimore_results <- baltimore_reg |>
  broom::tidy() |>
  mutate(
    OR = exp(estimate),  
    CI_upper = exp(estimate + 1.96 * std.error),  
    CI_lower = exp(estimate - 1.96 * std.error)  
  ) |>
  filter(term == "victim_sexMale") |>
  select(OR, CI_lower, CI_upper)  

baltimore_results
```

### All US cities GLM function 
Running a glm for each of the cities in the dataset, and extracting the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. 

```{r}
allcity_results <- homicide_df |>
  nest(data = -city_state) |>
  mutate(
    model = map(data, ~ glm(solved ~ victim_age + victim_sex + victim_race, data = .x, family = binomial())), 
    tidy_model = map(model, broom::tidy)
  ) |>
  select(-model, -data) |>
  unnest(cols = tidy_model) |>
  mutate(
    OR = exp(estimate), 
    CI_upper = exp(estimate + 1.96 * std.error),  
    CI_lower = exp(estimate - 1.96 * std.error)   
  ) |>
  filter(term == "victim_sexMale") |>
  select(city_state, OR, CI_upper, CI_lower)

allcity_results |>
  knitr::kable(digits = 4)
```

### Plot that shows the estimated ORs and CIs for each city

```{r}
allcity_results |>
  mutate(city_state = as.character(city_state),  
         city_state = fct_reorder(city_state, OR)) |>  
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +  
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "City/State", y = "Adjusted OR", title = "Adjusted Odds Ratio for Male vs Female Victims")
```

From this plot, we can see that New York, NY has the lowest adjusted OR comparing male to female homicide solved cases, and that Albuquerque, NM has the highest OR. The majority of the adjusted odds ratios are less than 1, indicating that for male victims, odds of having a solved homicide case are lower than that of female victims. 

# Problem 3 

### Loading data 

Here, we'll load the data and convert baby's sex, presence of malformations, mother's race, and father's race from numeric to factor variables:

```{r}
birthweight_df <- read_csv("birthweight.csv") |>
  janitor::clean_names() |>
  mutate(across(c(babysex, malform, mrace, frace), forcats::as_factor))
```

Let's also check for any missing values in the data: 

```{r}
missing_values = 
  birthweight_df |>
  summarize_all(~sum(is.na(.)))
```

### Creating the hypothetical model:

```{r}
proposed_model <- lm(bwt ~ babysex + bhead + blength + gaweeks + malform + mheight + pnumlbw + smoken, data = birthweight_df)

birthweight_df |>
  add_predictions(proposed_model) |>
  add_residuals(proposed_model) |>
  ggplot(aes(x = pred, y = resid)) +  
  geom_point(alpha = 0.2) +  
  geom_smooth(method = "lm", color = "blue") +  
  labs(
    x = "Fitted Values",
    y = "Residuals", 
    title = "Fitted Values vs. Residuals of Hypothesized Regression Model"
  )
```

I created this model by selecting predictors I thought would be most strongly associated with birthweight in grams based on what I have learned in maternal and child health courses, and predictors that seemed most associated with physical health/size of the baby. So, I picked sex of the baby, head circumfrence, gestational age, presence of malformations, mother's height, previous number of low birth weight babies, and average number of cigarettes smoked per day during pregnancy. When building a model, we want to make sure that predictors are likely to affect the outcome, so I selected variables that I believed would influence birthweight most. 

### Comparing main and interaction models to my original proposed model 

```{r}
cv_df <- crossv_mc(birthweight_df, 100) |>
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cvresidual_df <- cv_df |>
  mutate(
    proposed_model = map(train, \(x) lm(bwt ~ babysex + bhead + blength + gaweeks + malform + mheight + pnumlbw + smoken, data = x)), 
    main_model = map(train, \(x) lm(bwt ~ blength + gaweeks, data = x)),   
    interaction_model = map(train, \(x) lm(bwt ~ bhead + blength + babysex + bhead * blength * babysex, data = x)) 
  ) |>
  mutate(
    rmse_proposed = map2_dbl(proposed_model, test, rmse), 
    rmse_main = map2_dbl(main_model, test, rmse),
    rmse_interaction = map2_dbl(interaction_model, test, rmse)
  )
```

### Creating a plot comparing our models 

```{r}
cvresidual_df |>
  select(starts_with("rmse")) |>
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse") |>
  ggplot(aes(x = model, y = rmse, fill = model)) + 
  geom_violin() + 
  labs(x = "Model", 
       y = "RMSE",
       title = "RMSE by Regression Model")
```

Based on this violin plot, I can see that the interaction model and the proposed (hypothesized) model have the lowest RMSE, indicating the best and most accurate fit for predictions. However, the hypothesized model performed slightly better than the interaction model, with lower RMSE. The interaction model was a close second for the most accurate to use for birthweight predictions. 
